{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Load data</h2>\n",
    "The code is a modified version from the code in <a href=\"http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\">this</a> tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples: 300\n",
      "Possible categories: ['Games' 'Programming'] encoded to [0 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"../data/wikipedia_300.csv\")\n",
    "np_data = df.values\n",
    "\n",
    "# Split data into X and y\n",
    "X_raw = np_data[:,0:-1]\n",
    "# Convert class label strings to integers\n",
    "y_raw = np_data[:,-1]\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_raw)\n",
    "y = encoder.transform(y_raw)\n",
    "\n",
    "# Flatten input matrix to vector\n",
    "X_raw = X_raw.ravel()\n",
    "print(\"Examples: {}\".format(X_raw.shape[0]))\n",
    "print(\"Possible categories:\",np.unique(y_raw),\"encoded to\",np.unique(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Convert to bag of words</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 51162)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#count_vect = CountVectorizer(stop_words='english')\n",
    "count_vect = CountVectorizer()\n",
    "X = count_vect.fit_transform(X_raw)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Convert from occurences to frequencies</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 51162)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tf_transformer = TfidfTransformer().fit(X)\n",
    "X = tf_transformer.transform(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Function for evaluating model accuracy</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def evaluate(model):\n",
    "    print(\"-- Training data --\")\n",
    "    # train model on training dataset\n",
    "    model.fit(X, y)\n",
    "    # evaluate dataset\n",
    "    y_pred = model.predict(X)\n",
    "    # calculate accuracy\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "    # confusion matrix\n",
    "    print(\"Confusion Matrix:\")\n",
    "    conf_mx = confusion_matrix(y, y_pred)\n",
    "    print(conf_mx)\n",
    "    print(classification_report(y, y_pred))\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"-- 5-fold CV --\")\n",
    "    # 5-fold CV\n",
    "    y_pred = cross_val_predict(model, X, y, cv=5)\n",
    "    # calculate accuracy\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    print(\"Average accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "    # confusion matrix\n",
    "    print(\"Confusion Matrix:\")\n",
    "    conf_mx = confusion_matrix(y, y_pred)\n",
    "    print(conf_mx)\n",
    "    print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Naive Bayes</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Training data --\n",
      "Accuracy: 99.67%\n",
      "Confusion Matrix:\n",
      "[[149   1]\n",
      " [  0 150]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       150\n",
      "           1       0.99      1.00      1.00       150\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n",
      "\n",
      "-- 5-fold CV --\n",
      "Average accuracy: 96.00%\n",
      "Confusion Matrix:\n",
      "[[144   6]\n",
      " [  6 144]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       150\n",
      "           1       0.96      0.96      0.96       150\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       300\n",
      "   macro avg       0.96      0.96      0.96       300\n",
      "weighted avg       0.96      0.96      0.96       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "model = MultinomialNB(alpha=.01)\n",
    "evaluate(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>SVM</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Training data --\n",
      "Accuracy: 100.00%\n",
      "Confusion Matrix:\n",
      "[[150   0]\n",
      " [  0 150]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       150\n",
      "           1       1.00      1.00      1.00       150\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n",
      "\n",
      "-- 5-fold CV --\n",
      "Average accuracy: 95.33%\n",
      "Confusion Matrix:\n",
      "[[140  10]\n",
      " [  4 146]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95       150\n",
      "           1       0.94      0.97      0.95       150\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       300\n",
      "   macro avg       0.95      0.95      0.95       300\n",
      "weighted avg       0.95      0.95      0.95       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "model = svm.LinearSVC(random_state=42)\n",
    "evaluate(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Pipeline example</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Training data --\n",
      "Accuracy: 99.67%\n",
      "Confusion Matrix:\n",
      "[[149   1]\n",
      " [  0 150]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       150\n",
      "           1       0.99      1.00      1.00       150\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n",
      "\n",
      "-- 5-fold CV --\n",
      "Average accuracy: 95.67%\n",
      "Confusion Matrix:\n",
      "[[143   7]\n",
      " [  6 144]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96       150\n",
      "           1       0.95      0.96      0.96       150\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       300\n",
      "   macro avg       0.96      0.96      0.96       300\n",
      "weighted avg       0.96      0.96      0.96       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "X = X_raw.ravel()\n",
    "model = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
    "                  ('tfidf', TfidfTransformer()),\n",
    "                  ('clf', MultinomialNB(alpha=.01)),])\n",
    "evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
